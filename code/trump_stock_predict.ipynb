{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1698308935</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701461182</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1737479987</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1741160716</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1773561338</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43347</th>\n",
       "      <td>1273405198698975232</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/127...</td>\n",
       "      <td>Joe Biden was a TOTAL FAILURE in Government. H...</td>\n",
       "      <td>2020-06-17 19:00:32</td>\n",
       "      <td>23402</td>\n",
       "      <td>116377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43348</th>\n",
       "      <td>1273408026968457216</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/127...</td>\n",
       "      <td>Will be interviewed on @ seanhannity tonight a...</td>\n",
       "      <td>2020-06-17 19:11:47</td>\n",
       "      <td>11810</td>\n",
       "      <td>56659</td>\n",
       "      <td>@seanhannity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43349</th>\n",
       "      <td>1273442195161387008</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/127...</td>\n",
       "      <td>pic.twitter.com/3lm1spbU8X</td>\n",
       "      <td>2020-06-17 21:27:33</td>\n",
       "      <td>4959</td>\n",
       "      <td>19344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43350</th>\n",
       "      <td>1273442469066276864</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/127...</td>\n",
       "      <td>pic.twitter.com/vpCE5MadUz</td>\n",
       "      <td>2020-06-17 21:28:38</td>\n",
       "      <td>4627</td>\n",
       "      <td>17022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43351</th>\n",
       "      <td>1273442528411385858</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/127...</td>\n",
       "      <td>pic.twitter.com/VLlc0BHW41</td>\n",
       "      <td>2020-06-17 21:28:52</td>\n",
       "      <td>3951</td>\n",
       "      <td>14344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43352 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               link  \\\n",
       "0               1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
       "1               1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
       "2               1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
       "3               1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
       "4               1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
       "...                    ...                                                ...   \n",
       "43347  1273405198698975232  https://twitter.com/realDonaldTrump/status/127...   \n",
       "43348  1273408026968457216  https://twitter.com/realDonaldTrump/status/127...   \n",
       "43349  1273442195161387008  https://twitter.com/realDonaldTrump/status/127...   \n",
       "43350  1273442469066276864  https://twitter.com/realDonaldTrump/status/127...   \n",
       "43351  1273442528411385858  https://twitter.com/realDonaldTrump/status/127...   \n",
       "\n",
       "                                                 content                 date  \\\n",
       "0      Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
       "1      Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
       "2      Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
       "3      New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
       "4      \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
       "...                                                  ...                  ...   \n",
       "43347  Joe Biden was a TOTAL FAILURE in Government. H...  2020-06-17 19:00:32   \n",
       "43348  Will be interviewed on @ seanhannity tonight a...  2020-06-17 19:11:47   \n",
       "43349                         pic.twitter.com/3lm1spbU8X  2020-06-17 21:27:33   \n",
       "43350                         pic.twitter.com/vpCE5MadUz  2020-06-17 21:28:38   \n",
       "43351                         pic.twitter.com/VLlc0BHW41  2020-06-17 21:28:52   \n",
       "\n",
       "       retweets  favorites      mentions hashtags  \n",
       "0           510        917           NaN      NaN  \n",
       "1            34        267           NaN      NaN  \n",
       "2            13         19           NaN      NaN  \n",
       "3            11         26           NaN      NaN  \n",
       "4          1375       1945           NaN      NaN  \n",
       "...         ...        ...           ...      ...  \n",
       "43347     23402     116377           NaN      NaN  \n",
       "43348     11810      56659  @seanhannity      NaN  \n",
       "43349      4959      19344           NaN      NaN  \n",
       "43350      4627      17022           NaN      NaN  \n",
       "43351      3951      14344           NaN      NaN  \n",
       "\n",
       "[43352 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/trump_tweets.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow to only when trump was president (we'll try both later on)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['date'] >= '2017-01-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.7)\n",
      "Requirement already satisfied: optree in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zach/anaconda3/envs/torch/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "df = df.sort_values(by='date')\n",
    "\n",
    "\n",
    "sentences = df.content.to_list()\n",
    "dates = df.date.to_list()\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df with the embeddings and dates\n",
    "tweets_df = pd.DataFrame(embeddings)\n",
    "tweets_df['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get intraday data for S&P 500\n",
    "\n",
    "# https://www.kaggle.com/datasets/gratefuldata/intraday-stock-data-1-min-sp-500-200821?resource=download\n",
    "\n",
    "spy = pd.read_parquet('../data/spy.parquet')\n",
    "spy.date = pd.to_datetime(spy.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "\n",
    "def create_training_data(df, embeddings, tweets_df):\n",
    "\n",
    "    df['price_change'] = df['close'].pct_change().fillna(0)  # Calculate % change in price\n",
    "    df['volume_change'] = df['volume'].pct_change().fillna(0)\n",
    "\n",
    "    # Normalize price and volume data\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    df[['price_change', 'volume_change']] = scaler.fit_transform(df[['close', 'volume']])\n",
    "\n",
    "    # covert timestamp to seconds for proper sequence ordering\n",
    "    df['timestamp'] = pd.to_datetime(df['date']).astype(int) // 10**9\n",
    "    tweets_df['timestamp'] = pd.to_datetime(tweets_df['date']).astype(int) // 10**9\n",
    "    \n",
    "    \n",
    "    # merge the dataframes\n",
    "    df = pd.merge_asof(df.sort_values(\"timestamp\"),\n",
    "                   tweets_df.sort_values(\"timestamp\"),\n",
    "                   on=\"timestamp\",\n",
    "                   direction=\"backward\")  # backward fill tweets (important for time series)\n",
    "\n",
    "\n",
    "    #  replace NaNs with zeros\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    X = df[range(0, 384)]\n",
    "\n",
    "    # targe var \n",
    "    y = df['price_change'].shift(-1).fillna(0).values  # next minute's price change\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = create_training_data(spy, embeddings, tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM nn \n",
    "\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.from_numpy(X.values).float()\n",
    "y_tensor = torch.from_numpy(y).float().unsqueeze(1)\n",
    "\n",
    "\n",
    "# dataloader \n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "\n",
    "# Define LSTM Model\n",
    "class TweetImpactLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, num_layers=2):\n",
    "        super(TweetImpactLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x.unsqueeze(1))  # Adding batch dimension\n",
    "        return self.fc(lstm_out[:, -1, :])  # Predict next price change\n",
    "\n",
    "# Instantiate model\n",
    "input_dim = X.shape[1]  # Market data + tweet embedding size\n",
    "model = TweetImpactLSTM(input_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transformer model (takes forever)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.from_numpy(X.values).float()\n",
    "y_tensor = torch.from_numpy(y).float().unsqueeze(1)\n",
    "\n",
    "\n",
    "# dataloader \n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "\n",
    "# create basic class for trans model \n",
    "class Tweet_Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim=64, num_heads=4, num_layers=2, dropout=0.1):\n",
    "        super(Tweet_Transformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)  \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(model_dim, 1)  # Final layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Project to trans dim\n",
    "        x = x.unsqueeze(1)  #  sequence length dim\n",
    "        x = self.transformer_encoder(x)  # trough Trans \n",
    "        return self.fc(x[:, -1, :])  # Predict\n",
    "\n",
    "# Instantiate \n",
    "input_dim = X.shape[1]  # Market data + tweet embedding dim \n",
    "model = Tweet_Transformer(input_dim)\n",
    "\n",
    "# loss & optimiz\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train \n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Save model\n",
    "#torch.save(model.state_dict(), \"tweet_impact_transformer.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
